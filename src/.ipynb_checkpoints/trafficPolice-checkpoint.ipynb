{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09834b15-716b-407f-8bfd-43f3bcb0c24c",
   "metadata": {},
   "source": [
    "#CNN İLE TRAFİK KAZA PROJESİ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462efd76-863a-4f38-a9e5-2d01e5090027",
   "metadata": {},
   "source": [
    "veri yükleme ve hazırlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11026e31-5647-42a8-860a-81cb14201eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# CSV dosyasını okuma\n",
    "df = pd.read_csv('dangerLevelLabel.csv')\n",
    "\n",
    "# Veri artırma ve hazırlama\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "df['label'] = df['label'].astype(str)\n",
    "\n",
    "\n",
    "# Eğitim ve doğrulama veri setlerini hazırlama\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory='datapatch',\n",
    "    x_col='filename',\n",
    "    y_col='label',\n",
    "    target_size=(28, 28),\n",
    "    color_mode='rgb',\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory='datapatch',\n",
    "    x_col='filename',\n",
    "    y_col='label',\n",
    "    target_size=(28, 28),\n",
    "    color_mode='rgb',\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705ed8d7-f76d-47ec-b706-8dc834dcb90b",
   "metadata": {},
   "source": [
    "model oluşturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a054ba97-7cae-4e21-a703-0a196016b5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model oluşturma fonksiyonu\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 3)),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Veri artırma fonksiyonu\n",
    "def create_datagen():\n",
    "    return ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "# Modeli derleme fonksiyonu\n",
    "def compile_model(model):\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        optimizer=Adam(learning_rate=0.0005),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "# Callback'lerin oluşturulması\n",
    "def create_callbacks():\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0001)\n",
    "    return [early_stopping, reduce_lr]\n",
    "\n",
    "# Modeli ve veri artırma stratejilerini oluşturma\n",
    "model = create_model()\n",
    "datagen = create_datagen()\n",
    "compile_model(model)\n",
    "callbacks = create_callbacks()\n",
    "\n",
    "# Veri artırma ile veri yükleme\n",
    "train_datagen = datagen.flow_from_directory(\n",
    "    'datapatch', \n",
    "    target_size=(28, 28),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'  # kaza varsa 1, yoksa 0\n",
    ")\n",
    "\n",
    "validation_datagen = datagen.flow_from_directory(\n",
    "    'datapatch',\n",
    "    target_size=(28, 28),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'  # kaza varsa 1, yoksa 0\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7468ef1f-1b4f-4ea0-a167-9ca5e328b6c1",
   "metadata": {},
   "source": [
    "eğitme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e887b11-70d8-46af-97f1-9a01a30335b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model eğitimi\n",
    "history = model.fit(\n",
    "    train_datagen,\n",
    "    steps_per_epoch=train_datagen.n // 32,\n",
    "    epochs=50,\n",
    "    validation_data=validation_datagen,\n",
    "    validation_steps=validation_datagen.n // 32,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
